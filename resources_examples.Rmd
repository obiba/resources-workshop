---
title: "Tutorial: Using the resources in Opal and DataSHIELD"
author:
- name: Juan R. Gonzalez
  affiliation:
  - &isglobal Bioinformatics Research Group in Epidemiolgy (BRGE), Barcelona Insitute for Global Health (ISGlobal)
  email: juanr.gonzalez@isglobal.org
date: "`r Sys.Date()`"
output:
  BiocStyle::html_document
vignette: >
  %\VignetteIndexEntry{Tutorial: Using the resources in DataSHIELD}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE, purl=FALSE}
library(knitr)
BiocStyle::markdown()
options(width=100)
knitr::opts_chunk$set(comment="", warning=FALSE, message=FALSE, cache=TRUE)
```

# Introduction 

This tutorial aims to provide examples about how to deal with resources in Opal and DataSHIELD. More detailed information can be found in our bookdown [Orchestrating privacy-protected non-disclosive big data analyses of data from different resources with R and DataSHIELD](https://isglobal-brge.github.io/resource_bookdown/).

A quick demo of the resources is also available in [Tutorial: Resources in R](https://rpubs.com/ymarcon/713068).


# Getting started

This document can be reproduced by installing the following packages

```
install.packages("DSOpal")
devtools::install_github("datashield/dsBaseClient")
devtools::install_github("isglobal-brge/dsOmicsClient") 
```

Then the packages are loaded as usual

```{r load_packages}
library(DSOpal) 
library(dsBaseClient)
library(dsOmicsClient)
```


We have set up an [Opal demo site](http://opal-demo.obiba.org/) to illustrate how to perform some basic analyses using DataSHIELD as well as how to deal with different *resources* for 'omic data. The Opal server can be accessed with the credentials:

- username: `administrator`
- password: `password`


In this figure we can see all the projects available. 


```{r projects, echo=FALSE, fig.cap='Opal demo site available projects', fig.align='center', purl=FALSE}
knitr::include_graphics("fig/opal_projects.png")
```

This tutorial will mainly make use of the resources available at `RSRC` project

```{r resources, echo=FALSE, fig.cap='Resources available at Opal demo site of RSRC project',  fig.align='center', purl=FALSE}
knitr::include_graphics("fig/resources_rsrc.png")
```

In order to make the reader familiar with Opal we recommend visiting [the Opal online documentation](http://opaldoc.obiba.org/).



# Adding a new resource to the Opal server

The resources can be uploaded in the Opal server manually as described [here](https://isglobal-brge.github.io/resource_bookdown/tips-and-tricks.html#how-to-upload-a-new-resource-into-opal). However, it can also be done using R code as it is described in the following subsections. 

## Resource as a text file

Let us imagine that we have a `tsv` file that is stored in our hospital, server, cloud, GitHub repository or any other site. This file is containing information on several variables we want to analyze using DataSHIELD. Let us also imagine that this data is available at this URL: http://duffel.rail.bio/recount/TCGA/TCGA.tsv. This file encodes the phenotypes corresponding to 11,287 samples from [TCGA](https://www.cancer.gov/about-nci/organization/ccg/research/structural-genomics/tcga) that are available in the [Recount project](https://jhubiostatistics.shinyapps.io/recount/). 

Thanks to the **resources** this dataset is not necessary to be uploaded into the Opal server as a table anymore. We can analyze this data with DataSHIELD packages by creating a new resource as following. 

Let us start by login the Opal server. **NOTE** that this requires full permissions and, hence, we access with administrator rights

```{r}
o <- opal.login(username = 'administrator',
                password = 'password', 
                url = 'https://opal-demo.obiba.org')
```

TCGA dataset can be added as a new resource as following

```{r}
opal.resource_create(opal = o, 
                     project = 'RSRC', 
                     name = 'pheno_TCGA', 
                     url = 'http://duffel.rail.bio/recount/TCGA/TCGA.tsv', 
                     format = 'tsv')
```



We can see that this resource have been added to our project by

```{r}
opal.resources(o, project='RSRC')
```


We can test the resource assignment. First we assign the resource to an object called `client` 

```{r}
opal.assign.resource(o, 'client', 'RSRC.pheno_TCGA')
opal.execute(o, 'class(client)')
```

We see that this object is of class `TidyFileResourceClient`. The [resourcer](https://cran.r-project.org/web/packages/resourcer/index.html) package will be use then to "resolve" this resource and to load it into the R server as we will see later. 



We logout the connection

```{r}
opal.logout(o)
```

Then, we can analyze the data using DataSHIELD by making use of the created resource. We start by login the resource using an user who have DataSHIELD permissions to our Opal server (dsuser). 

```{r}
builder <- newDSLoginBuilder()
builder$append(server = 'study1', url = 'https://opal-demo.obiba.org', 
               user = 'dsuser', password = 'password', 
               resource = 'RSRC.pheno_TCGA', driver = 'OpalDriver')
logindata <- builder$build()
```


Then, we load the resource into R as `res`

```{r}
conns <- datashield.login(logins = logindata, 
                          assign = TRUE, 
                          symbol = 'res')
```

The `resourcer` package which is installed in the Opal server contains functions that facilitates the access of this data in the R server. In particular, we will have access to the resource as a data.frame called `pheno`. To this end, `as.resource.data.frame ()` function is used to coerce the resource (e.g. `ResourceClient` object) to a data frame.

```{r}
datashield.assign.expr(conns, symbol = 'pheno', 
                       expr = quote(as.resource.data.frame(res)))
```

```{r}
ds.class('pheno')
ds.dim('pheno')
```

```{r}
datashield.logout(conns)
```


## Resource as a Rdata file (data frame)

Now, let us assume that our resource is a data frame saved in a .Rdata file available at: https://github.com/isglobal-brge/brgedata/raw/master/data/asthma.rda. We can do similar steps to load the resource into the Opal server:

```{r}

o <- opal.login('administrator','password', 
                url='https://opal-demo.obiba.org')

opal.resource_create(opal = o, 
                     project = 'RSRC', 
                     name = 'asthma', 
                     url = 'https://github.com/isglobal-brge/brgedata/raw/master/data/asthma.rda', 
                     format = 'data.frame')
     
opal.assign.resource(o, 'client', 'RSRC.asthma')
opal.execute(o, 'class(client)')

opal.logout(o)
```

In that case the class of the `client` object is `RdataFileResourceClient` whose resolver is also implemented in the `resourcer` package. 

Then, we can analyze this data using DataSHIELD functions as usual. In that case, instead of using `as.resource.data.frame ()` (it is also possible to use it) we make use of the function `as.resource.object ()` which coerce the resource to an internal data object that depends on the implementation of this object.

```{r}
builder <- newDSLoginBuilder()
builder$append(server = 'study1', url = 'https://opal-demo.obiba.org', 
               user = 'dsuser', password = 'password', 
               resource = 'RSRC.asthma', driver = 'OpalDriver')
logindata <- builder$build()

conns <- datashield.login(logins = logindata, 
                          assign = TRUE, 
                          symbol = 'res')

datashield.assign.expr(conns, symbol = 'asthma', 
                       expr = quote(as.resource.object(res)))
```


Now, we can perform some standard statistical analysis in DataSHIELD as usual:

```{r}
ds.class('asthma')

ds.colnames('asthma')

ds.glm(casecontrol ~ rs1422993 + smoke + bmi, data='asthma', family='binomial')
```

Do not forget to close the connection after finishing the analyses

```{r}
datashield.logout(conns)
```



## Resource as an Rdata file (ExpressionSet)

One of the main advantages of using the resources as an R file is that it may contains any type of R object. Let us illustrate this by having an R file with an `ExpressionSet` object which is a [Bioconductor] class to encapsulate omic data along with phenotypic information and annotation. See [here](https://kasperdanielhansen.github.io/genbioconductor/html/ExpressionSet.html) for a description and this figure for a visual idea of how these objects are organized 


```{r eSet, echo=FALSE, fig.cap='ExpressionSet infrastructure', fig.align='center', out.width = '70%', purl=FALSE}
knitr::include_graphics("fig/eSet_vs_dataframe.png")
```

He have information on gene expression of 67,528 genes measured in 100 samples that are available in a `ExpressionSet` here: https://github.com/isglobal-brge/brgedata/raw/master/data/brge_gexp.rda. Let us illustrate how to create a resource in the Opal server having access to that data

```{r}
o <- opal.login('administrator','password', 
                url='https://opal-demo.obiba.org')

opal.resource_create(opal = o, 
                     project = 'RSRC', 
                     name = 'genexpr', 
                     url = 'https://github.com/isglobal-brge/brgedata/raw/master/data/brge_gexp.rda', 
                     format = 'ExpressionSet')

opal.assign.resource(o, 'client', 'RSRC.genexpr')
opal.execute(o, 'class(client)')
```

Now, we are ready to perform any data analysis using DataSHIELD as following. **NOTE** that in this case the R server must have installed those specific packages to deal with our specific class of objects. In that case, `ExpressionSet`s are managed with [`Biobase`](https://bioconductor.org/packages/release/bioc/html/Biobase.html) Bioconductor package. If so, the function `as.resource.object ()` which coerce the resource to an `ExpressionSet` that, in this case, will be available in the R server as an object called `eSet`.

```{r}
builder <- newDSLoginBuilder()
builder$append(server = 'study1', url = 'https://opal-demo.obiba.org', 
               user = 'dsuser', password = 'password', 
               resource = 'RSRC.genexpr', driver = 'OpalDriver')
logindata <- builder$build()

conns <- datashield.login(logins = logindata, 
                          assign = TRUE, 
                          symbol = 'res')

datashield.assign.expr(conns, symbol = 'eSet', 
                       expr = quote(as.resource.object(res)))
```

Then, we can use DataSHIELD fuctions as usual

```{r}
ds.class('eSet')
ds.dim('eSet')
```

In that case, if we execute

```{r error=TRUE}
ds.colnames('eSet')
```

we get an error, but ... we have developed a pair of DataSHIELD packages, called `dsOmics` and `dsOmicsClient` that allow us to deal with this type of objects in DataSHIELD. 

```{r}
dsOmicsClient::ds.featureData('eSet')
```

We finish the example by loggin out

```{r}
datashield.logout(conns)
```

# Using the resources in DataSHIELD 

## Data analysis combining different types of resources 

Here, we will use data from three studies that are available in our Opal demo repository. The three databases are called CNSIM1, CNSIM2, CNSIM3 and are available as three different resources: **mySQL database**, **SPSS file** and **CSV file** (see Figure \@ref(fig:resources)). This example mimics real situations where different hospitals or research centers manage their own databases containing harmonized data. Data correspond to three simulated datasets with different numbers of observations of 11 harmonized variables. They contain synthetic data based on a model derived from the participants of the 1958 Birth Cohort, as part of an obesity methodological development project. The available variables are:


```{r insert_table_variables, echo=FALSE}
vars <- readr::read_delim("fig/table_variables_cnsim.txt", delim=",")
kable(vars)
```

The aggregated analysis can be performed as follows. We first start by preparing the login data and the resources to assign 

```{r cnsim_multiple}
builder <- DSI::newDSLoginBuilder()
builder$append(server = "study1", url = "https://opal-demo.obiba.org", 
               user = "dsuser", password = "password", 
               resource = "RSRC.CNSIM1", driver = "OpalDriver")
builder$append(server = "study2", url = "https://opal-demo.obiba.org", 
               user = "dsuser", password = "password", 
               resource = "RSRC.CNSIM2", driver = "OpalDriver")
builder$append(server = "study3", url = "https://opal-demo.obiba.org", 
               user = "dsuser", password = "password", 
               resource = "RSRC.CNSIM3", driver = "OpalDriver")
logindata <- builder$build()
```

Then, we login and assign resources

```{r}
conns <- datashield.login(logins = logindata, assign = TRUE, symbol = "res")
``` 

The assigned objects are of class `ResourceClient` (and others)

```{r}
ds.class("res")
```

We then coerce the `ResourceClient` objects to data frames

```{r}
datashield.assign.expr(conns, symbol = "D", 
                       expr = quote(as.resource.data.frame(res, strict = TRUE)))
ds.class("D")
```

Now, we are ready to do usual DataSHIELD analyses

```{r}
ds.summary('D$LAB_HDL')
```

**NOTE**: vector types are not necessarily the same depending on the data reader that was used

```{r}
ds.class('D$GENDER')
ds.asFactor('D$GENDER', 'GENDER')
ds.summary('GENDER')
```

A logistic regression model can be fitted using privacy-protected analyses as if we would have the three datasets located in a single computer

```{r}
mod <- ds.glm("DIS_DIAB ~ LAB_TRIG + GENDER", data = "D" , family="binomial")
mod$coeff
```

Logout the connection 

```{r}
datashield.logout(conns)
```


## Data analysis using a remote computation server

Computation resources are resources on which tasks/commands can be triggered and from which resulting data can be retrieved. We can define a [SSH Resource](https://isglobal-brge.github.io/resource_bookdown/resourcer.html#computation-resources) which is accessible through a secure shell. The path part of the URL is the remote working directory. The available commands are defined by the exec query parameter as described in the [resources demo tutorial](https://rpubs.com/ymarcon/713068).

[PLINK](http://zzz.bwh.harvard.edu/plink/) is a program to perform whole genome association analysis (GWAS) in a computationally efficient manner. So, it may have sense to use this program to run the analyses instead of using R. 

PLINK data analysis requires to have genotype data in three files (.bed, .bim, .fam) and phenotype data in a different file. Therefore, the computation resource must contain the data and the commands that are allowed to be run in the server. This can be set up manually in the Opal server as indicated in the next figure

```{r plinkResources, echo=FALSE, fig.cap='Computation resource corresponding to PLINK example',  fig.align='center', out.width = '40%', purl=FALSE}
knitr::include_graphics("fig/plink_resource.png")
```

Notice that this resource are hosted at **plink-demo.obiba.org** in the folder `/home/master/brge`. This folder contains **brge.bed**, **brge.bim**, **brge.fam**, which are the three PLINK files and **brge.phe** file that encodes the phenotypic variables. The server also have installed PLINK.

This computation resource is already available at our demo Opal server (**brge_plink**) as you can see in figure \@ref(fig:resources)



The computation resource is a server side feature. So, we cannot see its functionallity using DataSHIELD. However, in order to easily illustrate how it works, let us create the resource in plain R 

```{r}
library(resourcer)
ssh.res <- newResource(
  url = "ssh://plink-demo.obiba.org:2222/home/master/brge?exec=ls,plink1,plink",
  identity = "master",
  secret = "master"
)
```

The resource connection client is resolved as follow:

```{r }
ssh.client <- newResourceClient(ssh.res)
class(ssh.client)
```

This type of client allows to issue shell commands through a SSH connection. In our case we can use:

```{r}
ssh.client$getAllowedCommands()
```

We can also see that the computation resource not only have PLINK program installed, but also our genomic and phenotypic data

```{r}
ssh.client$exec("ls")
```
Now, we are ready to run any PLINK command from R. Notice that in this case we want to assess association between the genotype data in bed format and use as phenotype the variable 'obese' that is in the file 'obesity.phe'. The sentence in a PLINK command would be (NOTE: we avoid --out to indicate the output file since the file will be available in R as a tibble).
  
```
  plink1 --bfile brge --assoc --pheno brge.phe --pheno-name obese --noweb
```

This could be done simply by executing

```{r}
ans <- ssh.client$exec('plink1', c('--bfile', 'brge', '--assoc', '--pheno', 'brge.phe', '--pheno-name', 'obese', '--noweb'))
ans
```

This is the output that is provided by PLINK and new output files have been created in the computation resource. These files can be downloaded in the R server by using the function

```{r eval=FALSE}
ssh.client$downloadFile()
```


We have implemented all these procedures in `dsOmics` package whose DataSHIELD client package is `dsOmicsClient`. Therefore, once the compuation resource is created in the Opal server we can perform such analyses using DataSHIELD by simply

```{r GWAS_shell_1}
  builder <- newDSLoginBuilder()
  builder$append(server = "study1", url = "https://opal-demo.obiba.org",
                 user = "dsuser", password = "password",
                 resource = "RSRC.brge_plink", driver = "OpalDriver")
  logindata <- builder$build()
```
  
Then we assign the resource to a symbol (i.e. R object) called `client` which is a ssh resource
  
```{r GWAS_shell_3}
  conns <- datashield.login(logins = logindata, assign = TRUE,
                            symbol = "client")
  ds.class("client")
```

and then call to `ds.PLINK ()` function. The arguments must be encapsulated in a single character without the command 'plink1'. The '--noweb' option is not necessary either.

```{r}
plink.arguments <- "--bfile brge --assoc --pheno brge.phe --pheno-name obese"
``` 

and then, the analyses are performed by

```{r}
library(dsOmicsClient)
ans.plink <- ds.PLINK("client", plink.arguments)
```

The object `ans.plink` contains the PLINK results at each server as well as the outuput provided by PLINK
  
```{r GWAS_shell_result1}
lapply(ans.plink, names)
  
head(ans.plink$study1$results)
  
ans.plink$study$plink.out
```
  

Let us finish our tutorial by removing the created resources

```{r}
opal.resource_delete(opal=o, project='RSRC', resource='pheno_TCGA')
opal.resource_delete(opal=o, project='RSRC', resource='asthma')
opal.resource_delete(opal=o, project='RSRC', resource='genexpr')
```

# Exercise

Physiological ecologists often analyze the responses of physiological or biochemical traits to environmental factors such as temperature, irradiance, water potential, or the concentrations of CO2, O2, and inorganic nutrients. Some researchers were interested in knowing the relationship between CO2 uptake (variable `uptake`) for six Echinochloa crus-galli plants from Quebec and six plants from Mississippi as a function of ambient CO2 concentration (variable `conc`). 

The CO2 uptake of six plants from Quebec and six plants from Mississippi was measured at several levels of ambient CO2 concentration. Half the plants of each type were chilled overnight before the experiment was conducted.  

Data cannot be shared between plants given confidentiality restrictions and researchers are interested in pooling both datasets via a virtually pooled-analysis. The scheme of the project can be seen in the next figure


```{r exercise, echo=FALSE, fig.cap='Carbon Dioxide Uptake in Quebec and Mississippi Grass Plants. Scheme of the proposed data analysis using DataSHIELD. Data of two locations are stored in different repositories and are available as .tsv files.', fig.align='center', purl=FALSE, out.width = '80%'}
knitr::include_graphics("fig/exercise.png")
```

Both datasets are .tsv files that are available in two different locations:

- **Quebec** (IGSlobal repository): https://raw.githubusercontent.com/isglobal-brge/brgedata/master/inst/extdata/co2_quebec.tsv

- **Mississippi** (OBiBa repository): https://raw.githubusercontent.com/obiba/resources-workshop/main/data/co2_mississippi.tsv

To the following steps to perform the required analysis:


1. Upload the two resources to the project `RSRC` available at the demo Opal site (https://opal-demo.obiba.org/, u:administrator, p:password). **IMPORTANT NOTE:** In order to avoid problems with duplicated names (all you are using the same server) give a name to the two resources like `boston_XXXXXX` and `mississippi_XXXXXX` and replace `XXXXXX` by **random** lower and upper letters (for example: boston_QrTyUZ and mississippi_AgbnYJ).
2. Login the connection to the two resources to DataSHIELD and assign the resources to objects having the same name as the resource name (in our case boston_QrTyUZ and mississippi_AgbnYJ).
3. Using `dsBaseClient` functions (for those new in DataSHIELD see `ls("package:dsBaseClient")`): 
     - Check the names of the variables of each data frame.
     - Check that the number of observations at each study (variable `Type`) is 42.
     - Create a "combined" scatterplot of the CO2 uptake (Y-axis) vs CO2 concentration (variable `conc`) (X-axix).
     - Run a linear model to investigate whether CO2 concentration can predicts CO2 uptake adjusting for chilled overnight factor (`Treatment`) and study (`Type`). 


# Session Info

```{r}
sessionInfo()
```